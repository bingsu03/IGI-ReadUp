# IGI AI-Team ReadUp List

## Large Language Model (LLM)

| Title | Description |
| ------ | ------ |
| [A critical assessment of using ChatGPT for extracting structured data from clinical notes](https://www.nature.com/articles/s41746-024-01079-8) (2024) | ChatGPT-3.5 efficiently extracts structured data from clinical notes, achieving up to 98.6% accuracy and outperforming traditional NLP methods without extensive manual annotation. |
| [BioMedRAG](https://arxiv.org/abs/2405.00465) (2024) | BiomedRAG improves biomedical NLP tasks by directly feeding retrieved documents into Large Language Models (LLMs), bypassing noise and enhancing performance on tasks like information extraction, text classification, link prediction, and question-answering. This straightforward approach enables better results across multiple datasets, outperforming previous systems in key metrics such as triple extraction. |
| [CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments](https://www.biorxiv.org/content/10.1101/2024.04.25.591003v1.full.pdf) (2024) | CRISPR-GPT is an advanced LLM tool that automates and improves CRISPR gene-editing design, making it easier for researchers to create and validate experiments while addressing ethical concerns. |
| [Microsoft prompt engineering tech](https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/) (2023) | Details Microsoftâ€™s methods for optimizing prompts to improve the performance of large language models. |
| [Prompt engineering is all you need](https://arxiv.org/pdf/2306.01987) (2024) | AdbGPT uses prompt-based Large Language Models to efficiently and effectively reproduce bugs from reports, surpassing current methods without manual patterns or training. |
| [Survey on mitigating Hallucination](https://arxiv.org/abs/2404.18930) (2024) | This survey examines hallucinations in multimodal large language models (MLLMs), reviewing methods for detecting and mitigating these inaccuracies, and highlighting challenges and future research directions. |
/

## Multimodal AI

| Title | Description |
| ------ | ------ |
| [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/pdf/2103.00020) (2021) | Shows that training on image-caption pairs allows for effective image representation learning, enabling competitive performance on various computer vision tasks without needing dataset-specific training. |
| [Med-gemini from DeepMind Google](https://arxiv.org/pdf/2404.18416) (2024) | Med-Gemini is a specialized multimodal model that outperforms GPT-4 on medical benchmarks, demonstrating state-of-the-art performance and significant improvements in various medical tasks and contexts. |
| [Segment Anything](https://arxiv.org/pdf/2304.02643) (2023) | The Segment Anything project presents a model and dataset with over 1 billion masks, achieving impressive zero-shot performance and adaptability for new tasks. |
| [ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks](https://arxiv.org/pdf/1908.02265) (2019) | ViLBERT extends BERT to a multimodal model for learning joint representations of images and text, achieving state-of-the-art performance on vision-and-language tasks through pretraining and minimal architectural adjustments. |
| [XMR: an explainable multimodal neural network for drug response prediction](https://pubmed.ncbi.nlm.nih.gov/37600972/) (2023) | The XMR model integrates visible and graph neural networks to predict drug responses in cancer, achieving superior accuracy and biological interpretability compared to existing models. |

